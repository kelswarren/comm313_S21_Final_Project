{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANALYSIS 4: Part of Speech & Year Descriptions (Year/2019/2020)\n",
    "\n",
    "In this notebook:\n",
    "  \n",
    "\n",
    "I explore the two corpora using part of speech tagging. I look at:\n",
    "- nouns\n",
    "- verbs\n",
    "- adjectives \n",
    "\n",
    "  \n",
    "Then, I look at the keyness for these lists of parts of speech to find out what is the most distinctive to each corpus. \n",
    "\n",
    "  \n",
    "I then look at the collocates/keyness for the words life/year as I realize people are talking about the context of their lives very differently between the two years.\n",
    "\n",
    "This allows me to add to my analysis about assessment of the life/year overall that is my secondary analysis to use in my data story."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_2019 = json.load(open(\"../data/cleaned/tweets_2019.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_2020 = json.load(open(\"../data/cleaned/tweets_2020.json\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_2019 = ''.join(tweets_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_2020 = ''.join(tweets_2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_2019 = tokenize(string_2019, lowercase = True, strip_chars = '.,!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_2020 = tokenize(string_2020, lowercase = True, strip_chars = '.,!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take out stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_stop_tokens_2019 = [word for word in tokens_2019 if (word not in stopwords)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_stop_tokens_2020 = [word for word in tokens_2020 if (word not in stopwords)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Freq lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq_2019 = Counter(tokens_2019)\n",
    "bigram_freq_2019 = Counter(get_bigram_tokens(tokens_2019))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq_2020 = Counter(tokens_2020)\n",
    "bigram_freq_2020 = Counter(get_bigram_tokens(tokens_2020))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part of Speech tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to make tagged token objects for each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_tokens_2019 = pos_tag(tokens_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_2019 = sent_tokenize(string_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_tokens_2020 = pos_tag(tokens_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_2020 = sent_tokenize(string_2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VERBS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verbs 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbs_2019 = []\n",
    "for word, tag in tagged_tokens_2019:\n",
    "    if tag.startswith('V'):\n",
    "        verbs_2019.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "verb_dist_2019=Counter(verbs_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('is', 2767),\n",
       " ('thanksgiving', 2519),\n",
       " ('have', 2235),\n",
       " ('be', 2187),\n",
       " ('are', 1932),\n",
       " ('i', 1176),\n",
       " ('am', 1095),\n",
       " ('appreciate', 895),\n",
       " ('give', 790),\n",
       " ('love', 759),\n",
       " ('was', 702),\n",
       " ('#thanksgiving', 589),\n",
       " ('do', 587),\n",
       " ('been', 574),\n",
       " ('has', 568),\n",
       " ('blessed', 545),\n",
       " ('know', 504),\n",
       " ('being', 500),\n",
       " ('hope', 494),\n",
       " ('get', 426)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verb_dist_2019.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verbs 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbs_2020 = []\n",
    "for word, tag in tagged_tokens_2020:\n",
    "    if tag.startswith('V'):\n",
    "        verbs_2020.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "verb_dist_2020 = Counter(verbs_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('is', 2747),\n",
       " ('have', 2253),\n",
       " ('thanksgiving', 2197),\n",
       " ('be', 2141),\n",
       " ('are', 1792),\n",
       " ('i', 1238),\n",
       " ('am', 1123),\n",
       " ('appreciate', 923),\n",
       " ('love', 802),\n",
       " ('was', 728),\n",
       " ('has', 706),\n",
       " ('been', 706),\n",
       " ('give', 671),\n",
       " ('do', 591),\n",
       " ('know', 562),\n",
       " ('blessed', 505),\n",
       " ('get', 468),\n",
       " ('#thanksgiving', 466),\n",
       " ('being', 462),\n",
       " ('hope', 457)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verb_dist_2020.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can calculate the keyness for these lists of verbs. \n",
    "\n",
    "This will tell us which verbs (actions) are distinctive to each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD                     Corpus A Freq.Corpus B Freq.Keyness\n",
      "============================================================\n",
      "thanksgiving             2519      2197      20.032\n",
      "loving                   64        26        16.322\n",
      "wouldn’t                 35        9         16.250\n",
      "ate                      27        6         14.323\n",
      "#thanksgiving            589       466       13.613\n",
      "#gratitude               73        35        13.424\n",
      "excited                  25        6         12.394\n",
      "#blessed                 130       82        10.664\n",
      "knew                     37        15        9.470\n",
      "spend                    124       80        9.292\n",
      "give                     790       671       8.972\n",
      "y’all                    23        7         8.893\n",
      "told                     51        28        6.651\n"
     ]
    }
   ],
   "source": [
    "calculate_keyness(verb_dist_2019, verb_dist_2020, top=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD                     Corpus A Freq.Corpus B Freq.Keyness\n",
      "============================================================\n",
      "stay                     138       51        42.144\n",
      "dropped                  41        5         32.368\n",
      "thinking                 48        16        16.945\n",
      "looks                    61        24        16.890\n",
      "god                      292       204       16.252\n",
      "has                      706       568       15.855\n",
      "miss                     66        29        15.032\n",
      "been                     706       574       14.476\n",
      "help                     142       89        12.603\n",
      "you’ve                   30        9         12.062\n",
      "guys                     116       70        11.785\n",
      "helped                   104       61        11.608\n",
      "praying                  30        10        10.591\n",
      "changed                  39        16        10.065\n",
      "learn                    52        25        9.842\n",
      "following                37        15        9.746\n",
      "check                    57        29        9.461\n",
      "passed                   29        11        8.511\n",
      "deserves                 29        11        8.511\n",
      "#givethanks              41        20        7.512\n",
      "became                   19        6         7.185\n",
      "bless                    96        63        7.107\n",
      "friend                   17        5         6.992\n",
      "drop                     20        7         6.609\n"
     ]
    }
   ],
   "source": [
    "calculate_keyness(verb_dist_2020, verb_dist_2019, top=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What do we find?\n",
    "\n",
    "The verbs distinctive to 2019 are more reflective of the holiday of thanksgiving:\n",
    " - loving \n",
    " - ate\n",
    " - spend\n",
    " - give\n",
    " \n",
    "The verbs distinctive to 2002 are reflective of the struggles of 2020:\n",
    " - stay\n",
    " - dropped \n",
    " - miss\n",
    " - helped\n",
    " - changed\n",
    " - learn\n",
    " - became \n",
    " \n",
    "Overall, there is a lot more substantive action in the collocates from 2020, suggesting that people are talking about real happenings in these tweets. In other words, perhaps the verbs in 2019 are functioning more as \"fluff\", and in 2020 as more practical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOUNS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nouns 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns_2019 = []\n",
    "for word, tag in tagged_tokens_2019:\n",
    "    if tag.startswith('N'):\n",
    "        nouns_2019.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_dist_2019=Counter(nouns_2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nouns 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns_2020 = []\n",
    "for word, tag in tagged_tokens_2020:\n",
    "    if tag.startswith('N'):\n",
    "        nouns_2020.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_dist_2020=Counter(nouns_2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frequency lists are not great to compare. Let's look at keyness of the nouns again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD                     Corpus A Freq.Corpus B Freq.Keyness\n",
      "============================================================\n",
      "day                      1700      1265      45.518\n",
      "•                        109       31        42.510\n",
      "cowboys                  49        10        26.320\n",
      "la                       38        6         24.490\n",
      "jones                    35        5         23.944\n",
      "chronicles               77        27        22.806\n",
      "endureth                 46        13        18.071\n",
      "friends                  893       692       17.110\n",
      "store                    32        7         16.222\n",
      "troops                   32        7         16.222\n",
      "family                   1710      1413      16.222\n",
      "season                   186       115       13.784\n",
      "l                        25        5         13.646\n",
      "😂                        43        15        12.834\n",
      "🍁                        51        20        12.606\n",
      "@                        183       116       12.203\n",
      "fun                      71        34        11.667\n",
      "practice                 68        32        11.644\n",
      "dallas                   32        10        11.124\n",
      "tv                       32        10        11.124\n",
      "night                    102       57        10.915\n",
      "road                     24        6         10.748\n",
      "part                     149       94        10.143\n",
      "course                   59        28        9.905\n",
      "relationship             21        5         9.861\n",
      "hands                    35        13        9.478\n",
      "friday                   43        18        9.430\n",
      "abundance                28        9         9.380\n",
      "yours                    50        23        9.018\n",
      "#love                    74        40        8.785\n",
      "feast                    46        21        8.438\n",
      "babies                   25        8         8.425\n",
      "#happythanksgivng        38        16        8.240\n",
      "pic                      21        6         8.147\n",
      "grace                    57        29        8.036\n",
      "she’s                    26        9         7.850\n",
      "lord;                    24        8         7.649\n",
      "event                    29        11        7.587\n",
      "mercy                    74        42        7.525\n",
      "@realdonaldtrump         71        40        7.400\n",
      "opportunities            57        30        7.317\n",
      "everyday                 38        17        7.284\n",
      "we're                    76        44        7.222\n",
      "difference               30        12        7.160\n",
      "tomorrow                 77        45        7.078\n",
      "–                        45        22        7.031\n",
      "importance               23        8         6.895\n",
      "🦃                        130       87        6.705\n",
      "y                        26        10        6.645\n"
     ]
    }
   ],
   "source": [
    "calculate_keyness(noun_dist_2019, noun_dist_2020, top=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD                     Corpus A Freq.Corpus B Freq.Keyness\n",
      "============================================================\n",
      "year                     1060      720       82.020\n",
      "workers                  73        12        51.496\n",
      "im                       148       66        36.145\n",
      "stay                     87        30        31.686\n",
      "courts                   50        10        30.992\n",
      "💯                        38        5         30.248\n",
      "check                    44        9         26.828\n",
      "gates                    48        11        26.774\n",
      "album                    55        15        26.187\n",
      "grateful                 723       577       23.879\n",
      "moots                    34        6         22.951\n",
      "tweet                    148       82        22.383\n",
      "lot                      283       195       20.619\n",
      "generations              36        8         20.591\n",
      "n                        37        10        17.775\n",
      "care                     104       57        16.182\n",
      "congratulations          42        14        15.976\n",
      "health                   203       141       14.287\n",
      "heroes                   25        6         13.408\n",
      "prayers                  59        28        12.773\n",
      "name                     91        53        11.982\n",
      "truth                    49        22        11.817\n",
      "democracy                30        10        11.411\n",
      "nation                   51        24        11.230\n",
      "americans                62        32        11.182\n",
      "plate                    36        14        11.064\n",
      "🥺                        31        11        10.868\n",
      "states                   29        10        10.562\n",
      "parents                  97        61        10.024\n",
      "praise                   53        27        9.851\n",
      "wisdom                   34        14        9.544\n",
      "amen                     44        21        9.416\n",
      "light                    41        19        9.307\n",
      "thread                   52        27        9.247\n",
      "way                      282       226       9.047\n",
      "@youtube                 22        7         8.857\n",
      "harry                    22        7         8.857\n",
      "stream                   36        16        8.847\n",
      "kind                     130       92        8.413\n",
      "thing                    188       143       8.395\n",
      "memory                   32        14        8.092\n",
      "neighbors                21        7         7.988\n",
      "sorry                    47        25        7.887\n",
      "please                   105       72        7.809\n",
      "✨                        24        9         7.786\n",
      "tl                       34        16        7.487\n",
      "feels                    17        5         7.483\n",
      "hello                    17        5         7.483\n",
      "&amp;                    589       525       7.234\n",
      "election                 18        6         6.847\n"
     ]
    }
   ],
   "source": [
    "calculate_keyness(noun_dist_2020, noun_dist_2019, top = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does this show us?\n",
    "\n",
    "Again, we see the year reflected in these tweets. \n",
    "\n",
    "For the 2019 corpus, nouns are more focused on traditional expressions of gratitude on thanksgiving\n",
    "- family, friends, relationship, abundance, feast \n",
    "\n",
    "\n",
    "For the 2020 corpus, we have nouns that really tell the story of the pandemic:\n",
    "- workers, stay, care, heroes prayers\n",
    "\n",
    "For 2020, we also have nouns related to the election\n",
    "- election, democracy, courts, states, truth, americans\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adjectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjectives 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_2019 = []\n",
    "for word, tag in tagged_tokens_2019:\n",
    "    if tag.startswith('JJ'):\n",
    "        adj_2019.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_dist_2019=Counter(adj_2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjectives 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_2020 = []\n",
    "for word, tag in tagged_tokens_2020:\n",
    "    if tag.startswith('JJ'):\n",
    "        adj_2020.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_dist_2020=Counter(adj_2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collocation for adjectives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD                     Corpus A Freq.Corpus B Freq.Keyness\n",
      "============================================================\n",
      "full                     224       120       28.878\n",
      "wonderful                412       273       24.362\n",
      "#gobblegobble            32        7         16.612\n",
      "🦃                        63        26        14.762\n",
      "amazing                  289       199       14.088\n",
      "#thankful                291       209       11.147\n",
      "#blackfriday             23        6         10.127\n",
      "south                    22        6         9.243\n",
      "#grateful                216       153       8.991\n",
      "gobble                   28        10        8.343\n",
      "turkey                   69        38        8.200\n",
      "@                        40        19        7.020\n"
     ]
    }
   ],
   "source": [
    "calculate_keyness(adj_dist_2019, adj_dist_2020, top = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD                     Corpus A Freq.Corpus B Freq.Keyness\n",
      "============================================================\n",
      "safe                     326       116       110.355\n",
      "u                        320       204       29.515\n",
      "different                113       54        23.120\n",
      "healthy                  109       52        22.382\n",
      "difficult                58        19        21.894\n",
      "sorry                    39        11        17.481\n",
      "tough                    54        21        16.042\n",
      "#thanksgivingday         32        9         14.386\n",
      "crazy                    65        30        14.282\n",
      "willing                  27        7         13.171\n",
      "positive                 80        43        12.449\n",
      "normal                   22        5         12.074\n",
      "white                    56        28        10.379\n",
      "#bethankful              29        10        10.245\n",
      "mental                   39        17        9.557\n",
      "only                     68        38        9.538\n",
      "alex                     18        5         8.198\n",
      "own                      96        64        7.446\n",
      "other                    225       177       7.286\n",
      "weird                    25        10        7.102\n",
      "sad                      39        20        6.816\n",
      "fam                      23        9         6.767\n",
      "same                     143       106       6.692\n"
     ]
    }
   ],
   "source": [
    "calculate_keyness(adj_dist_2020, adj_dist_2019, top = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does this mean? How does it add to our discussion comparing gratitude in the two years?\n",
    "\n",
    "For adjectives distinctive to 2019...\n",
    "- wonderful\n",
    "- amazing \n",
    "- turkey \n",
    "- grateful, thankful\n",
    "\n",
    "For adjectives distinctive to 2020...\n",
    "- related to COVID: safe, healthy, normal\n",
    "- challenges: different, difficult, sorry, weird, sad, tough, crazy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What did the PoS analysis tell us?\n",
    "\n",
    "It told us that the contexts in which words function in the two corpora is different and feels very reflective of the differences between the years overall. Most basically, that 2020 was a very hard year for many compared to 2019."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking at reflections on the year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can look at the collocates around \"year\" to see how people are referencing the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "coll_yr_19 = collocates(no_stop_tokens_2019,\"year\", win=[4,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "coll_yr_19_freq = Counter([word for word in no_stop_tokens_2019 if (word in coll_yr_19)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('thanksgiving', 4123),\n",
       " ('thankful', 3101),\n",
       " ('grateful', 2295),\n",
       " ('thanks', 2094),\n",
       " ('happy', 1926),\n",
       " ('family', 1710),\n",
       " ('day', 1700),\n",
       " ('love', 1492),\n",
       " ('blessings', 1203),\n",
       " ('i’m', 1158),\n",
       " ('appreciate', 1107),\n",
       " ('give', 1028),\n",
       " ('&amp;', 1006),\n",
       " ('thank', 1001),\n",
       " ('friends', 984),\n",
       " ('life', 979),\n",
       " ('gratitude', 974),\n",
       " ('appreciation', 889),\n",
       " ('everyone', 844),\n",
       " ('people', 839),\n",
       " ('god', 838),\n",
       " ('today', 825),\n",
       " ('lucky', 799),\n",
       " ('much', 789),\n",
       " ('us', 788),\n",
       " ('thankfulness', 779),\n",
       " (\"i'm\", 745),\n",
       " ('year', 720),\n",
       " ('blessing', 708),\n",
       " ('hope', 677)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll_yr_19_freq.most_common()[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "coll_yr_20 = collocates(no_stop_tokens_2020,\"year\", win=[4,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "coll_yr_20_freq = Counter([word for word in no_stop_tokens_2020 if (word in coll_yr_20)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('thanksgiving', 3599),\n",
       " ('thankful', 2817),\n",
       " ('grateful', 2367),\n",
       " ('thanks', 1994),\n",
       " ('happy', 1897),\n",
       " ('love', 1449),\n",
       " ('family', 1413),\n",
       " ('day', 1265),\n",
       " ('i’m', 1170),\n",
       " ('blessings', 1168),\n",
       " ('appreciate', 1151),\n",
       " ('&amp;', 1135),\n",
       " ('year', 1060),\n",
       " ('thank', 1014),\n",
       " ('gratitude', 989),\n",
       " ('#oreninyourarea', 924),\n",
       " ('appreciation', 917),\n",
       " ('god', 916),\n",
       " ('much', 893),\n",
       " ('give', 868),\n",
       " ('life', 838),\n",
       " ('people', 816),\n",
       " ('us', 800),\n",
       " ('everyone', 777),\n",
       " ('friends', 767),\n",
       " ('thankfulness', 763),\n",
       " ('today', 750),\n",
       " ('blessing', 715),\n",
       " ('one', 697),\n",
       " ('like', 696)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll_yr_20_freq.most_common()[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD                     Corpus A Freq.Corpus B Freq.Keyness\n",
      "============================================================\n",
      "day                      1700      1265      83.441\n",
      "thanksgiving             4123      3599      60.740\n",
      "2019                     78        17        45.017\n",
      "family                   1710      1413      42.003\n",
      "friends                  984       767       36.753\n",
      "full                     224       120       36.417\n",
      "cowboys                  73        19        36.113\n",
      "wonderful                414       278       32.864\n",
      "thankful                 3101      2817      28.018\n",
      "🍁                        80        30        25.712\n",
      "give                     1028      868       20.999\n",
      "season                   186       115       19.992\n",
      "amazing                  366       272       18.089\n",
      "🦃                        213       141       17.897\n",
      "life                     979       838       17.609\n",
      "#grateful                261       183       17.213\n",
      "#thanksgiving            618       505       16.580\n",
      "part                     149       94        14.952\n",
      "spend                    134       82        14.900\n",
      "i'm                      745       633       14.372\n",
      "work                     291       217       14.118\n",
      "grace                    63        30        13.383\n",
      "every                    548       454       13.178\n",
      "course                   59        28        12.620\n",
      "lucky                    799       693       12.596\n",
      "home                     216       156       12.378\n",
      "#turkeyday               83        46        12.359\n",
      "best                     337       265       11.890\n",
      "#thankful                360       286       11.855\n",
      "she’s                    46        20        11.636\n",
      "back                     248       187       11.310\n",
      "we're                    134       90        10.628\n",
      "great                    507       427       10.595\n",
      "#gratitude               326       260       10.450\n",
      "feast                    54        27        10.333\n",
      "fun                      84        50        10.195\n",
      "share                    199       149       9.441\n",
      "without                  209       160       8.725\n",
      "#blessed                 141       101       8.412\n",
      "thanks                   2094      1994      8.379\n",
      "everyday                 167       124       8.293\n",
      "incredible               76        47        8.163\n",
      "someone                  132       94        8.099\n",
      "call                     88        57        8.032\n",
      "memories                 64        38        7.828\n",
      "business                 61        36        7.599\n",
      "#thankfulness            134       97        7.592\n",
      "ever                     222       176       7.416\n",
      "today                    825       750       7.377\n",
      "bit                      79        51        7.300\n"
     ]
    }
   ],
   "source": [
    "calculate_keyness(coll_yr_19_freq, coll_yr_20_freq, top=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD                     Corpus A Freq.Corpus B Freq.Keyness\n",
      "============================================================\n",
      "2020                     198       36        116.828\n",
      "safe                     331       120       94.088\n",
      "stay                     233       83        68.045\n",
      "year                     1060      720       51.963\n",
      "im                       271       166       21.296\n",
      "you’ve                   119       58        18.997\n",
      "different                113       54        18.918\n",
      "healthy                  109       52        18.322\n",
      "u                        464       329       17.819\n",
      "✨                        44        13        16.543\n",
      "though                   124       65        16.355\n",
      "tweet                    164       97        14.718\n",
      "alone                    78        36        14.145\n",
      "tough                    54        21        13.688\n",
      "#thanksgivingday         56        23        12.877\n",
      "lot                      284       196       12.770\n",
      "crazy                    74        36        11.868\n",
      "heroes                   25        6         11.735\n",
      "changed                  41        16        10.331\n",
      "helped                   104       61        9.618\n",
      "health                   203       141       8.804\n",
      "care                     142       92        8.787\n",
      "passed                   29        11        7.666\n",
      "despite                  51        26        7.259\n",
      "weird                    30        12        7.239\n",
      "cook                     42        20        7.090\n",
      "#givethanks              280       212       6.811\n",
      "mental                   40        19        6.792\n",
      "shelter                  21        7         6.755\n",
      "thinking                 61        34        6.698\n"
     ]
    }
   ],
   "source": [
    "calculate_keyness(coll_yr_20_freq, coll_yr_19_freq, top=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does this tell us?\n",
    "\n",
    "This makes it really clear that there is such a different analysis of the two years. We can see that the collocates around \"year\" in 2020 are much more grounded in the context of the pandemic (and negative) then those in 2019 which are a lot more positive/general.\n",
    "\n",
    "In 2019, the words are more positive (amazing, wonderful) or about thanksgiving/gratitude (thankful, thanksigving, season). \n",
    "\n",
    "In 2020, the distinctive words around year were about enduring the year (during, through, been, stay) and descriptions of its relativeness to other years (different, weird, crazy, tough)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"2020\" vs. \"2019\":\n",
    "\n",
    "Now let's look directly at how much each of these years are talked about and in what contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq_2019[\"2019\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq_2020[\"2020\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is really interesting. We see that 2020 appears so much more in the 2020 corpus than 2019 does in the 2019 corpus. This reflects how much 2020 has become a trope in culture because it has been so unique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can also look at how 2019 and 2020 compare in context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "coll_19_2 = collocates(no_stop_tokens_2019,\"2019\", win=[4,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "coll_19_freq_2 = Counter([word for word in no_stop_tokens_2019 if (word in coll_19_2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('thanksgiving', 4123),\n",
       " ('thankful', 3101),\n",
       " ('grateful', 2295),\n",
       " ('thanks', 2094),\n",
       " ('happy', 1926),\n",
       " ('family', 1710),\n",
       " ('day', 1700),\n",
       " ('love', 1492),\n",
       " ('blessings', 1203),\n",
       " ('i’m', 1158),\n",
       " ('give', 1028),\n",
       " ('&amp;', 1006),\n",
       " ('thank', 1001),\n",
       " ('friends', 984),\n",
       " ('life', 979),\n",
       " ('gratitude', 974),\n",
       " ('appreciation', 889),\n",
       " ('god', 838),\n",
       " ('today', 825),\n",
       " ('lucky', 799),\n",
       " ('much', 789),\n",
       " ('us', 788),\n",
       " ('thankfulness', 779),\n",
       " ('year', 720),\n",
       " ('blessing', 708),\n",
       " ('hope', 677),\n",
       " ('one', 674),\n",
       " ('many', 642),\n",
       " ('good', 639),\n",
       " ('blessed', 622)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll_19_freq_2.most_common()[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "coll_20_2 = collocates(no_stop_tokens_2020,\"2020\", win=[4,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "coll_20_freq_2 = Counter([word for word in no_stop_tokens_2020 if (word in coll_20_2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('thanksgiving', 3599),\n",
       " ('thankful', 2817),\n",
       " ('grateful', 2367),\n",
       " ('thanks', 1994),\n",
       " ('happy', 1897),\n",
       " ('love', 1449),\n",
       " ('family', 1413),\n",
       " ('day', 1265),\n",
       " ('i’m', 1170),\n",
       " ('blessings', 1168),\n",
       " ('appreciate', 1151),\n",
       " ('&amp;', 1135),\n",
       " ('year', 1060),\n",
       " ('thank', 1014),\n",
       " ('gratitude', 989),\n",
       " ('appreciation', 917),\n",
       " ('god', 916),\n",
       " ('much', 893),\n",
       " ('give', 868),\n",
       " ('life', 838),\n",
       " ('people', 816),\n",
       " ('us', 800),\n",
       " ('everyone', 777),\n",
       " ('friends', 767),\n",
       " ('thankfulness', 763),\n",
       " ('today', 750),\n",
       " ('blessing', 715),\n",
       " ('one', 697),\n",
       " ('like', 696),\n",
       " ('lucky', 693)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll_20_freq_2.most_common()[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_19 = calculate_keyness(coll_19_freq_2, coll_20_freq_2, print_table=False, top=-1, keyness_threshold=-100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=' float:left; width: 40%; text-align: center'>\n",
       "        <h3>Distinctive Words Around 2019</h3>\n",
       "        \n",
       "            <div style=\"font-size: 28.984532646528827px; color: green; margin-bottom: 2px; float: left; \n",
       "            margin: 10px; padding: 2px; background-color: #f7f7f7; border-radius: 6px\">\n",
       "            thanksgiving</div>\n",
       "            \n",
       "\n",
       "            <div style=\"font-size: 27.438774552053694px; color: green; margin-bottom: 2px; float: left; \n",
       "            margin: 10px; padding: 2px; background-color: #f7f7f7; border-radius: 6px\">\n",
       "            day</div>\n",
       "            \n",
       "\n",
       "            <div style=\"font-size: 26.64130627214498px; color: green; margin-bottom: 2px; float: left; \n",
       "            margin: 10px; padding: 2px; background-color: #f7f7f7; border-radius: 6px\">\n",
       "            thankful</div>\n",
       "            \n",
       "\n",
       "            <div style=\"font-size: 25.698980220559143px; color: green; margin-bottom: 2px; float: left; \n",
       "            margin: 10px; padding: 2px; background-color: #f7f7f7; border-radius: 6px\">\n",
       "            family</div>\n",
       "            \n",
       "\n",
       "            <div style=\"font-size: 23.971081509169963px; color: green; margin-bottom: 2px; float: left; \n",
       "            margin: 10px; padding: 2px; background-color: #f7f7f7; border-radius: 6px\">\n",
       "            friends</div>\n",
       "            \n",
       "\n",
       "            <div style=\"font-size: 23.442346599375167px; color: green; margin-bottom: 2px; float: left; \n",
       "            margin: 10px; padding: 2px; background-color: #f7f7f7; border-radius: 6px\">\n",
       "            thanks</div>\n",
       "            \n",
       "\n",
       "            <div style=\"font-size: 22.73392871659388px; color: green; margin-bottom: 2px; float: left; \n",
       "            margin: 10px; padding: 2px; background-color: #f7f7f7; border-radius: 6px\">\n",
       "            give</div>\n",
       "            \n",
       "\n",
       "            <div style=\"font-size: 22.211658556880224px; color: green; margin-bottom: 2px; float: left; \n",
       "            margin: 10px; padding: 2px; background-color: #f7f7f7; border-radius: 6px\">\n",
       "            life</div>\n",
       "            \n",
       "\n",
       "            <div style=\"font-size: 22.013170908530565px; color: green; margin-bottom: 2px; float: left; \n",
       "            margin: 10px; padding: 2px; background-color: #f7f7f7; border-radius: 6px\">\n",
       "            happy</div>\n",
       "            \n",
       "\n",
       "            <div style=\"font-size: 21.287391308088427px; color: green; margin-bottom: 2px; float: left; \n",
       "            margin: 10px; padding: 2px; background-color: #f7f7f7; border-radius: 6px\">\n",
       "            grateful</div>\n",
       "            \n",
       "\n",
       "            <div style=\"font-size: 21.172496082453613px; color: green; margin-bottom: 2px; float: left; \n",
       "            margin: 10px; padding: 2px; background-color: #f7f7f7; border-radius: 6px\">\n",
       "            love</div>\n",
       "            \n",
       "\n",
       "            <div style=\"font-size: 21.05396870369132px; color: green; margin-bottom: 2px; float: left; \n",
       "            margin: 10px; padding: 2px; background-color: #f7f7f7; border-radius: 6px\">\n",
       "            full</div>\n",
       "            \n",
       "\n",
       "            <div style=\"font-size: 20.94310592234431px; color: green; margin-bottom: 2px; float: left; \n",
       "            margin: 10px; padding: 2px; background-color: #f7f7f7; border-radius: 6px\">\n",
       "            @</div>\n",
       "            \n",
       "\n",
       "            <div style=\"font-size: 20.91811661679209px; color: green; margin-bottom: 2px; float: left; \n",
       "            margin: 10px; padding: 2px; background-color: #f7f7f7; border-radius: 6px\">\n",
       "            lucky</div>\n",
       "            \n",
       "\n",
       "            <div style=\"font-size: 20.818908482154374px; color: green; margin-bottom: 2px; float: left; \n",
       "            margin: 10px; padding: 2px; background-color: #f7f7f7; border-radius: 6px\">\n",
       "            #thanksgiving</div>\n",
       "            \n",
       "\n",
       "            <div style=\"font-size: 20.570109664121343px; color: green; margin-bottom: 2px; float: left; \n",
       "            margin: 10px; padding: 2px; background-color: #f7f7f7; border-radius: 6px\">\n",
       "            2019</div>\n",
       "            \n",
       "\n",
       "            <div style=\"font-size: 20.104506941066735px; color: green; margin-bottom: 2px; float: left; \n",
       "            margin: 10px; padding: 2px; background-color: #f7f7f7; border-radius: 6px\">\n",
       "            blessings</div>\n",
       "            \n",
       "\n",
       "            <div style=\"font-size: 20.002713873214564px; color: green; margin-bottom: 2px; float: left; \n",
       "            margin: 10px; padding: 2px; background-color: #f7f7f7; border-radius: 6px\">\n",
       "            today</div>\n",
       "            \n",
       "\n",
       "            <div style=\"font-size: 18.91504686041997px; color: green; margin-bottom: 2px; float: left; \n",
       "            margin: 10px; padding: 2px; background-color: #f7f7f7; border-radius: 6px\">\n",
       "            #grateful</div>\n",
       "            \n",
       "\n",
       "            <div style=\"font-size: 18.73480601063217px; color: green; margin-bottom: 2px; float: left; \n",
       "            margin: 10px; padding: 2px; background-color: #f7f7f7; border-radius: 6px\">\n",
       "            season</div>\n",
       "            \n",
       "\n",
       "            <div style=\"font-size: 18.63178180850413px; color: green; margin-bottom: 2px; float: left; \n",
       "            margin: 10px; padding: 2px; background-color: #f7f7f7; border-radius: 6px\">\n",
       "            🦃</div>\n",
       "            \n",
       "\n",
       "            <div style=\"font-size: 18.620910265454253px; color: green; margin-bottom: 2px; float: left; \n",
       "            margin: 10px; padding: 2px; background-color: #f7f7f7; border-radius: 6px\">\n",
       "            #thankful</div>\n",
       "            \n",
       "\n",
       "            <div style=\"font-size: 18.61949062150366px; color: green; margin-bottom: 2px; float: left; \n",
       "            margin: 10px; padding: 2px; background-color: #f7f7f7; border-radius: 6px\">\n",
       "            i’m</div>\n",
       "            \n",
       "\n",
       "            <div style=\"font-size: 18.4660986428424px; color: green; margin-bottom: 2px; float: left; \n",
       "            margin: 10px; padding: 2px; background-color: #f7f7f7; border-radius: 6px\">\n",
       "            best</div>\n",
       "            \n",
       "\n",
       "            <div style=\"font-size: 18.304417902067552px; color: green; margin-bottom: 2px; float: left; \n",
       "            margin: 10px; padding: 2px; background-color: #f7f7f7; border-radius: 6px\">\n",
       "            blessed</div>\n",
       "            \n",
       "\n",
       "            <div style=\"font-size: 18.28721705862964px; color: green; margin-bottom: 2px; float: left; \n",
       "            margin: 10px; padding: 2px; background-color: #f7f7f7; border-radius: 6px\">\n",
       "            -</div>\n",
       "            \n",
       "\n",
       "            <div style=\"font-size: 18.057120988851086px; color: green; margin-bottom: 2px; float: left; \n",
       "            margin: 10px; padding: 2px; background-color: #f7f7f7; border-radius: 6px\">\n",
       "            #gratitude</div>\n",
       "            \n",
       "\n",
       "            <div style=\"font-size: 17.79966468793792px; color: green; margin-bottom: 2px; float: left; \n",
       "            margin: 10px; padding: 2px; background-color: #f7f7f7; border-radius: 6px\">\n",
       "            thank</div>\n",
       "            \n",
       "\n",
       "            <div style=\"font-size: 17.662783633302627px; color: green; margin-bottom: 2px; float: left; \n",
       "            margin: 10px; padding: 2px; background-color: #f7f7f7; border-radius: 6px\">\n",
       "            thankfulness</div>\n",
       "            \n",
       "\n",
       "            <div style=\"font-size: 17.578302066380648px; color: green; margin-bottom: 2px; float: left; \n",
       "            margin: 10px; padding: 2px; background-color: #f7f7f7; border-radius: 6px\">\n",
       "            gratitude</div>\n",
       "            </div>\n",
       "       <div style='width: 40%; padding-left: 20px; float: left; '>\n",
       "       <h3 style=\"text-align: center\">Distinctive Words Aroud 2020</h3>\n",
       "        \n",
       "            <div style=\"font-size: 4.656815095687361px; color: purple; margin-bottom: 2px; float: left; \n",
       "            margin: 10px; padding: 2px; background-color: #f7f7f7; border-radius: 6px\">\n",
       "            nov</div>\n",
       "            \n",
       "\n",
       "            <div style=\"font-size: 3.750664544602584px; color: purple; margin-bottom: 2px; float: left; \n",
       "            margin: 10px; padding: 2px; background-color: #f7f7f7; border-radius: 6px\">\n",
       "            something</div>\n",
       "            \n",
       "\n",
       "            <div style=\"font-size: 2.7625948930303585px; color: purple; margin-bottom: 2px; float: left; \n",
       "            margin: 10px; padding: 2px; background-color: #f7f7f7; border-radius: 6px\">\n",
       "            focus</div>\n",
       "            \n",
       "\n",
       "            <div style=\"font-size: 2.6090410543862355px; color: purple; margin-bottom: 2px; float: left; \n",
       "            margin: 10px; padding: 2px; background-color: #f7f7f7; border-radius: 6px\">\n",
       "            honest</div>\n",
       "            \n",
       "\n",
       "            <div style=\"font-size: 2.5599587848755094px; color: purple; margin-bottom: 2px; float: left; \n",
       "            margin: 10px; padding: 2px; background-color: #f7f7f7; border-radius: 6px\">\n",
       "            sometimes</div>\n",
       "            \n",
       "\n",
       "            <div style=\"font-size: 1.644466299602767px; color: purple; margin-bottom: 2px; float: left; \n",
       "            margin: 10px; padding: 2px; background-color: #f7f7f7; border-radius: 6px\">\n",
       "            national</div>\n",
       "            \n",
       "\n",
       "            <div style=\"font-size: 1.6068736994445771px; color: purple; margin-bottom: 2px; float: left; \n",
       "            margin: 10px; padding: 2px; background-color: #f7f7f7; border-radius: 6px\">\n",
       "            world</div>\n",
       "            \n",
       "\n",
       "            <div style=\"font-size: 1.3824030627983022px; color: purple; margin-bottom: 2px; float: left; \n",
       "            margin: 10px; padding: 2px; background-color: #f7f7f7; border-radius: 6px\">\n",
       "            looking</div>\n",
       "            \n",
       "\n",
       "            <div style=\"font-size: 1.0568307489865878px; color: purple; margin-bottom: 2px; float: left; \n",
       "            margin: 10px; padding: 2px; background-color: #f7f7f7; border-radius: 6px\">\n",
       "            better</div>\n",
       "            \n",
       "\n",
       "            <div style=\"font-size: 0.47485489106159173px; color: purple; margin-bottom: 2px; float: left; \n",
       "            margin: 10px; padding: 2px; background-color: #f7f7f7; border-radius: 6px\">\n",
       "            strong</div>\n",
       "            \n",
       "\n",
       "            <div style=\"font-size: -0.3034886901637141px; color: purple; margin-bottom: 2px; float: left; \n",
       "            margin: 10px; padding: 2px; background-color: #f7f7f7; border-radius: 6px\">\n",
       "            next</div>\n",
       "            \n",
       "\n",
       "            <div style=\"font-size: -1.1311241779776444px; color: purple; margin-bottom: 2px; float: left; \n",
       "            margin: 10px; padding: 2px; background-color: #f7f7f7; border-radius: 6px\">\n",
       "            ko</div>\n",
       "            \n",
       "\n",
       "            <div style=\"font-size: -1.2372427082522783px; color: purple; margin-bottom: 2px; float: left; \n",
       "            margin: 10px; padding: 2px; background-color: #f7f7f7; border-radius: 6px\">\n",
       "            pray</div>\n",
       "            \n",
       "\n",
       "            <div style=\"font-size: -1.3648605878978437px; color: purple; margin-bottom: 2px; float: left; \n",
       "            margin: 10px; padding: 2px; background-color: #f7f7f7; border-radius: 6px\">\n",
       "            video</div>\n",
       "            \n",
       "\n",
       "            <div style=\"font-size: -3.458750111780273px; color: purple; margin-bottom: 2px; float: left; \n",
       "            margin: 10px; padding: 2px; background-color: #f7f7f7; border-radius: 6px\">\n",
       "            guys</div>\n",
       "            \n",
       "\n",
       "            <div style=\"font-size: -4.641352737238016px; color: purple; margin-bottom: 2px; float: left; \n",
       "            margin: 10px; padding: 2px; background-color: #f7f7f7; border-radius: 6px\">\n",
       "            way</div>\n",
       "            \n",
       "\n",
       "            <div style=\"font-size: -5.879589998217306px; color: purple; margin-bottom: 2px; float: left; \n",
       "            margin: 10px; padding: 2px; background-color: #f7f7f7; border-radius: 6px\">\n",
       "            taught</div>\n",
       "            \n",
       "\n",
       "            <div style=\"font-size: -6.01777886384863px; color: purple; margin-bottom: 2px; float: left; \n",
       "            margin: 10px; padding: 2px; background-color: #f7f7f7; border-radius: 6px\">\n",
       "            didn’t</div>\n",
       "            \n",
       "\n",
       "            <div style=\"font-size: -6.606003387856861px; color: purple; margin-bottom: 2px; float: left; \n",
       "            margin: 10px; padding: 2px; background-color: #f7f7f7; border-radius: 6px\">\n",
       "            went</div>\n",
       "            \n",
       "\n",
       "            <div style=\"font-size: -9.216246232999485px; color: purple; margin-bottom: 2px; float: left; \n",
       "            margin: 10px; padding: 2px; background-color: #f7f7f7; border-radius: 6px\">\n",
       "            jesus</div>\n",
       "            \n",
       "\n",
       "            <div style=\"font-size: -16.847009624498664px; color: purple; margin-bottom: 2px; float: left; \n",
       "            margin: 10px; padding: 2px; background-color: #f7f7f7; border-radius: 6px\">\n",
       "            via</div>\n",
       "            \n",
       "\n",
       "            <div style=\"font-size: -18.094873952677098px; color: purple; margin-bottom: 2px; float: left; \n",
       "            margin: 10px; padding: 2px; background-color: #f7f7f7; border-radius: 6px\">\n",
       "            missed</div>\n",
       "            \n",
       "\n",
       "            <div style=\"font-size: -25.162093616342727px; color: purple; margin-bottom: 2px; float: left; \n",
       "            margin: 10px; padding: 2px; background-color: #f7f7f7; border-radius: 6px\">\n",
       "            brought</div>\n",
       "            \n",
       "\n",
       "            <div style=\"font-size: -50.35746909910287px; color: purple; margin-bottom: 2px; float: left; \n",
       "            margin: 10px; padding: 2px; background-color: #f7f7f7; border-radius: 6px\">\n",
       "            rest</div>\n",
       "            \n",
       "\n",
       "            <div style=\"font-size: -6.789046123186551px; color: purple; margin-bottom: 2px; float: left; \n",
       "            margin: 10px; padding: 2px; background-color: #f7f7f7; border-radius: 6px\">\n",
       "            happened</div>\n",
       "            \n",
       "\n",
       "            <div style=\"font-size: -2.300573865961817px; color: purple; margin-bottom: 2px; float: left; \n",
       "            margin: 10px; padding: 2px; background-color: #f7f7f7; border-radius: 6px\">\n",
       "            health</div>\n",
       "            \n",
       "\n",
       "            <div style=\"font-size: -0.8224319995666438px; color: purple; margin-bottom: 2px; float: left; \n",
       "            margin: 10px; padding: 2px; background-color: #f7f7f7; border-radius: 6px\">\n",
       "            u</div>\n",
       "            \n",
       "\n",
       "            <div style=\"font-size: 1.8329472989143438px; color: purple; margin-bottom: 2px; float: left; \n",
       "            margin: 10px; padding: 2px; background-color: #f7f7f7; border-radius: 6px\">\n",
       "            thread</div>\n",
       "            \n",
       "\n",
       "            <div style=\"font-size: 8.192214689362936px; color: purple; margin-bottom: 2px; float: left; \n",
       "            margin: 10px; padding: 2px; background-color: #f7f7f7; border-radius: 6px\">\n",
       "            year</div>\n",
       "            \n",
       "\n",
       "            <div style=\"font-size: 19.829583623209594px; color: purple; margin-bottom: 2px; float: left; \n",
       "            margin: 10px; padding: 2px; background-color: #f7f7f7; border-radius: 6px\">\n",
       "            safe</div>\n",
       "            </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_keyitems(dist_19,30, c1='green', c2='purple', \n",
    "              corpusA='Distinctive Words Around 2019', corpusB='Distinctive Words Aroud 2020')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD                     Corpus A Freq.Corpus B Freq.Keyness\n",
      "============================================================\n",
      "2020                     198       36        82.997\n",
      "safe                     331       120       52.769\n"
     ]
    }
   ],
   "source": [
    "calculate_keyness(coll_20_freq_2, coll_19_freq_2, top=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does this tell us?\n",
    "\n",
    "Once again, we see how reflections of \"year\" in 2019/2020 and the direct comparison of \"2019\"/\"2020\" yield the same results we've been seeing in Tweets in 2019 that are more around Thanksgiving, gratitude, and positive descriptions of the year. In 2020, they are more practical. The fact that \"safe\" is the distinctive word around \"2020\" is reflective of what the year has been for many."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
